---
title: 'Use Databricks for synthetic data'
description: 'To use Databricks as a data source or destination for your synthetic data, you need to create a Databricks connector.'
---

import Image from 'next/image';
import { Callout } from 'nextra/components';
import { Tabs } from 'nextra/components';
import { CustomCallout } from '@components/custom-callout';

# Use Databricks for synthetic data

To use Databricks as a data source or destination for your synthetic data, you need to create a Databricks connector.

## Prerequisites

To create a Databricks connector, you need to obtain your SQL Warehouse connection details, a Databricks catalog name, and a personal access token for Databricks. The linked sections below provide step-by-step guidance on how to complete the prerequisites.

- [Database connection details in Databricks](#get-connection-details-for-your-databricks-sql-warehouse)
- [Catalog name in Databricks](#get-databricks-catalog-name)
- [Personal access token in Databricks](#create-a-databricks-personal-access-token)
  <CustomCallout>**Note**: As MOSTLY AI leverages [Unity Catalog Volumes in Databricks](https://www.databricks.com/blog/announcing-general-availability-unity-catalog-volumes) for data ingestion, make sure that the user associated with the access token in your destination connector is granted the `CREATE TABLE` and `CREATE VOLUME` privileges.</CustomCallout>

### Get connection details for your Databricks SQL Warehouse

1. In Databricks, open the workspace that contains the SQL Warehouse you want to use.
2. Open the sidebar menu again and select **SQL Warehouses**.
3. From the list, open the SQL warehouse you want to use for synthetic data.
4. Select the **Connection details** tab.
5. Copy the necessary connection details (hostname, port, protocol, and HTTP path) for the MOSTLY AI Databricks connector.

### Get Databricks catalog name

1. From the Databricks sidebar menu, select **Data**.
2. Copy the name of the catalog you want to use in MOSTLY AI.

### Create a Databricks personal access token

1. In Databricks, open your account menu and select **User Settings**.
2. Under **Settings**, select **Developer**.
3. Click **Manage** for **Access Tokens**.
4. Click **Generate new token**.
5. In the **Generate new token** window, enter a name that identifies where you intend to use the token.

   <Callout>Adjust the expiration of the token in the **Lifetime (days)** box.</Callout>

6. Click **Generate**.
7. Copy the access token and save it in a secure location.
   <Callout type="warning">Before you close the window, save the token in a location you can access later.</Callout>

## Create a Databricks connector

<Tabs items={['UI', 'Synthetic Data SDK']}>
<Tabs.Tab>
Create a new Databricks connector from the **Connectors** page.

**Steps**

1.  From the **Connectors** page, select **Databricks** under the **Connect your data** header.
2.  On the **New connector** modal, configure the connector.

| Field            | Description                                                                      |
| ---------------- | -------------------------------------------------------------------------------- |
| **Name**         | Enter a name that you can distinguish from other connectors.                     |
| **Access type**  | Select whether you want to use the connector as a **source** or **destination**. |
| **Host**         | Your SQL warehouse server hostname.                                              |
| **HTTP path**    | Your SQL warehouse HTTP path.                                                    |
| **Access token** | Your Databricks personal access token.                                           |
| **Catalog**      | The name of your Databricks catalog.                                             |

3.  Click **Save** to save your new Databricks connector.
    - MOSTLY AI tests the connection. If you see an error, check the connection details, update them, and click **Save** again.<br /><br />
    - You can click **Save anyway** to save the connector and disregard any errors.

</Tabs.Tab>
<Tabs.Tab>

If you use the Synthetic Data SDK, create a Databricks connector with `mostly.connect()` and provide a connector configuration dictionary as shown below.

```python copy filename="python"
c = mostly.connect({
    "name": "Databricks Connector",
    "type": "DATABRICKS",
    "access_type": "SOURCE",
    "config": {
        "host": "HOST.databricks.com",
        "http_path": "/sql/1.0/warehouses/KEY",
        "catalog": "CATALOG_NAME"
    },
    "secrets": {
        "access_token": "******"
    },
    "test_connection": True
})
```

</Tabs.Tab>
</Tabs>

## Authenticate with a Service principal

To use a Service principal account to access original data stored in Databricks, you need to create a Databricks connector with a Service principal account.

<Tabs items={['UI', 'Synthetic Data SDK']}>
<Tabs.Tab>

The Databricks connector configuration includes configuration details that support the authentication with a Service principal account.

**Steps**

1.  To use a Service principal for authentication in your Databricks connector, select the **Authenticate with Service Principal** checkbox.
2.  Configure the Databricks connector.

| Field             | Description                                                                      |
| ----------------- | -------------------------------------------------------------------------------- |
| **Name**          | Enter a name that you can distinguish from other connectors.                     |
| **Access type**   | Select whether you want to use the connector as a **source** or **destination**. |
| **Host**          | Your SQL warehouse server hostname.                                              |
| **HTTP path**     | Your SQL warehouse HTTP path.                                                    |
| **Catalog**       | The name of your Databricks catalog.                                             |
| **Tenant ID**     | Your tenant ID.                                                                  |
| **Client ID**     | Your client ID.                                                                  |
| **Client secret** | Your client secret.                                                              |

3.  Click **Save** to save your new Databricks connector.
    - MOSTLY AI tests the connection. If you see an error, check the connection details, update them, and click **Save** again.<br /><br />
    - You can click **Save anyway** to save the connector disregarding any errors.

</Tabs.Tab>
<Tabs.Tab>

If you use the Synthetic Data SDK, you can create a Databricks connector with a Service principal account with the code snippet below.

```python copy filename="python"
config={
    "name": "Databricks connector with Service principals",
    "type": "DATABRICKS",
    "access_type": "SOURCE",
    "config": {
        "host": "INSERT_DATABRICKS_HOST",
        "http_path": "INSERT_HTTP_PATH",
        "account_name": "INSERT_ACCOUNT_NAME",
        "catalog": "INSERT_DATABRICKS_CATALOG",
        "tenant_id": "INSERT_TENANT_ID",
        "client_id": "INSERT_CLIENT_ID",
    },
    "secrets": {
        "client_secret": "INSERT_CLIENT_SECRET"
    },
    "test_connection": True

}
c = mostly.connect(config)
```

</Tabs.Tab>
</Tabs>

**What's next**

Depending on whether you created a **source** or a **destination** connector, you can use the connector as:

- [Data source](../use/data-source) for a new generator
- [Data destination](../use/data-destination) for a new synthetic dataset
