---
title: 'Conditional simulation'
description: 'With conditional simulation, you can create a new synthetic dataset that is conditioned on a seed dataset you provide. This is also known as conditional simulation.'
---

import Image from 'next/image';
import { Callout } from 'nextra/components';
import { Tabs } from 'nextra/components';

# Conditional simulation

With **_conditional simulation_**, you can create a new synthetic dataset that is conditioned on a seed dataset you provide. This is also known as **_conditional simulation_**.

The seed dataset acts as context for the generation of the new synthetic dataset. With a seed dataset, you can define as context the **columns**, **values**, and **their distributions** that you want to use to conditionally generate the rest of the columns in the synthetic dataset.

The new synthetic dataset will still be statistically representative, but within the context of the seed dataset. The privacy of the new synthetic dataset then depends on the privacy of the provided seed.

A synthetic dataset generated with seed is **_partially synthetic_**.

- The columns in the seed dataset that you provide as context remain the same in the generated synthetic dataset.
- The rest of the columns (non-seed) are generated synthetically and are conditioned on the values in the seed dataset.
- If you use Personally Identifiable Information (PII) in the seed dataset, that information will be available "as-is" in the generated synthetic dataset. In such cases, treat the synthetic data with the same care you apply for personal data.
- The seed dataset is deleted immediately after the synthetic dataset is generated.

## Generate a synthetic dataset with seed

For conditional simulation, start a new synthetic dataset and provide a seed dataset.

**Prerequisites**

- A [trained generator](/generators/train).
- A **seed dataset** with the characteristics listed below.
  - The **seed column names must match** those in the table used for generator training.
  - **Seed categorical columns must contain the same categories** as in the dataset used for training. For example, `Female` and `Male` categories in a `sex` column must match exactly the ones used for training.
  - Bear in mind that **conditionally-generated numeric and datetime values are kept within the range of the original data**. For example, if the column `age` ranges between `18` and `80` in the original data, age `15` in a seed dataset will be clipped to `18` in the conditionally-generated data.

<Tabs items={['UI', 'Synthetic Data SDK']}>
<Tabs.Tab>
If you use the web application, you can upload a seed dataset from the **Sample size** options after you start a new synthetic dataset.

1.  Start a new synthetic dataset.
2.  On the **Synthetic dataset configuration** page, expand the subject table.
3.  Expand **Conditional simulation**.
4.  Click **Choose file**.
    <Image src="/docimages/synthetic-datasets/seeded-generation/02-click-upload-seed-file.webp" alt="Conditional simulation - Sample size - Click Upload file" width={800} height={150} />
5.  (Optional) Adjust the rest of the generation settings.
6.  Click **Start generation** in the upper right.

</Tabs.Tab>
<Tabs.Tab>

    If you use the Synthetic Data SDK, use the `seed` parameter of `mostly.generate()` to specify a seed dataset.

```python filename="python" copy
sd = mostly.generate(generator=g, seed=seed)
```

</Tabs.Tab>
</Tabs>

## Examples

The three examples below showcase what you can achieve with conditional simulation.

<Callout>The examples below are also available as a [Jupyter Notebook](https://colab.research.google.com/github/mostly-ai/mostly-tutorials/blob/dev/conditional-generation/conditional-generation.ipynb). You can also find it in our [Tutorials](/tutorials) section.</Callout>

1. [Perform multi-column dataset rebalancing](#rebalance-datasets-with-conditional-simulation). You create a seed dataset with two columns that have a new distribution. You then use the seed for conditional simulation and see how the rest of the columns are impacted by the rebalancing.
2. [Generate partially synhetic geo data](#generate-partially-synthetic-geographical-data). Use the original geographical coordinates from the original training dataset to generate the remaining columns as synthetic data.
3. [Generate synthetic names](#generate-synthetic-names). Train a generator on the [baseball/players] table and generate the first names and last names of baseball players by using a seed dataset that contains the country of origin of the players.

### Rebalance datasets with conditional simulation

In this example, you learn how to rebalance the US Census dataset with seed generation, where the seed dataset contains an equal distribution of females and males and an uncorrelated income attribute. The goal is to remove the gender gap and see how the rest of the attributes in the original dataset change in the generated synthetic dataset.

The information below provides a sequence of steps with an explanation of each step. You can use the code snippets in a Jupyter Notebook and adjust them as you see fit.

**Prerequistes**

To reproduce this example, you need the following Python packages.

- [MOSTLY AI Synthetic Data SDK](https://pypi.org/project/mostlyai/)
- [Pandas](https://pandas.pydata.org/)
- [NumPy](https://numpy.org/)
- [Matplotlib](https://matplotlib.org/)

To install in a Jupyter Notebook environment, use the following:

```bash copy
!pip install mostlyai pandas numpy matplotlib
```

**Steps**

1. Import the Python packages needed for this example.
   ```python filename="python" copy
   from mostlyai.sdk import MostlyAI
   import pandas as pd
   import numpy as np
   ```
1. Get an API key and instantiate the Synthetic Data SDK. For details, see [here](/python-sdk#get-an-api-key).
   ```python filename="python" copy
   mostly = MostlyAI(api_key="INSERT_API_KEY")
   ```
1. Train a generator on the US Adult dataset or get an existing one.
   - Train a new generator.
     ```python filename="python" copy
     df = pd.read_csv('http://docs.mostly.ai/public-datasets/us-census-income.csv.gz')
     g = mostly.train(data=df, name="Tutorial Conditional Simulation - US Census")
     ```
   - Get an existing generator trained on the US Adult dataset.
     ```python filename="python" copy
     g = mostly.generators.get("INSERT_GENERATOR_ID")
     ```
1. Create a seed dataset.<br />
   Create the seed dataset with a Pandas DataFrame. Use [NumPy](https://numpy.org/) to randomly generate the seed values.<br />
   For the `sex` attribute, you create a 50/50 split between `Male` and `Female`.<br />
   For the `income` attribute, you keep the share of low- and high-income earners constant. However, you can see how you can randomize between men and women, effectively removing the gender income gap.

   ```python filename="python" copy
   np.random.seed(1)

   n = 48_842 # generate the same number of records as in the original dataset
   p_inc = (df.income=='>50K').mean() # get the probability of the high-income category
   seed = pd.DataFrame({
       'sex': np.random.choice(['Male', 'Female'], n, p=[.5, .5]), # generate 50/50 split between Females and Males
       'income': np.random.choice(['<=50K', '>50K'], n, p=[1-p_inc, p_inc]), # generate income categories based on the probabilities of the original dataset
   })
   ```

1. Generate a rebalanced dataset with the seed dataset as context.
   ```python filename="python" copy
   sd = mostly.generate(generator=g, seed=seed)
   ```
1. Use [Matplotlib](https://matplotlib.org/) to compare the age distribution of records from the original vs rebalanced dataset.
   ```python filename="python" copy
   import matplotlib.pyplot as plt
   plt.xlim(10, 95)
   plt.title('Female Age Distribution')
   plt.xlabel('Age')
   df[df.sex=='Female'].age.plot.kde(color='black', bw_method=0.2)
   syn[syn.sex=='Female'].age.plot.kde(color='#24db96', bw_method=0.2)
   plt.legend({'original': 'black', 'synthetic': '#24db96'})
   plt.show()
   ```

To meet the criteria of removing the gender income gap, the generated synthetic records for women are now significantly older as shown in the chart.

<Image src="/docimages/synthetic-datasets/seeded-generation/01-example-01-chart.webp" alt="Conditional simulation - Example 01 - Chart - Rebalance dataset" width={450} height={500} />

You can explore other shifts in the distributions that are generated as a consequence of the provided seed data.

### Generate partially synthetic geographical data

For this use case, you will be using [2019 AirBnB listings for Manhattan](https://colab.research.google.com/github/mostly-ai/mostly-tutorials/blob/dev/conditional-generation/conditional-generation.ipynb#refs). The dataset consists of 48,895 records, and 10 mixed-type columns, with two of those representing the latitude and longitude of the listing. You will use this dataset to create synthetic attributes for all the actual locations, that were contained in the original.

**Prerequistes**

To reproduce this example, you need the following Python packages.

- [MOSTLY AI Synthetic Data SDK](https://pypi.org/project/mostlyai/)
- [Pandas](https://pandas.pydata.org/)
- [Matplotlib](https://matplotlib.org/)

To install in a Jupyter Notebook environment, use the following:

```bash copy
!pip install mostlyai pandas matplotlib
```

**Steps**

1. Import the Python packages needed for this example.
   ```python filename="python" copy
   from mostlyai.sdk import MostlyAI
   import pandas as pd
   import matplotlib.pyplot as plt
   ```
2. Read the original dataset into a Pandas DataFrame object.
   ```python filename="python" copy
   # fetch original data
   df_orig = pd.read_csv('https://github.com/mostly-ai/public-demo-data/raw/dev/airbnb/airbnb.csv.gz')
   df_orig
   ```
3. Pre-process the original data.<br />
   MOSTLY AI expect latitude and longitude in a single table column. Because of this, you need to concatenate the latitude and longitude in a single column.<br />
   In this example, you do not create artifical seed data. Instead, you use real data: the concatenated `LAT_LONG` variable and the `neighbourhood` variable as a seed dataframe.

   ```python filename="python" copy
   df = df_orig.copy()

   # concatenate latitude and longitude to "LAT, LONG" format
   df['LAT_LONG'] = df['latitude'].astype(str) + ', ' + df['longitude'].astype(str)
   df = df.drop(columns=['latitude', 'longitude'])

   # define list of columns, on which we want to condition on
   seed_cols = ['neighbourhood', 'LAT_LONG']

   # create dataframe that will be used as seed
   df_seed = df[seed_cols]
   display(df_seed.head())
   ```

4. Train a generator with the pre-processed AirBnB dataset.

   ```python filename="python" copy
   # Train a generator on the pre-processed AirBnB data
   config = {
       'name': 'Conditional Simulation Tutorial AirBnB',
       'tables': [{
           'name': 'AirBnB',
           'data': df,
           'tabular_model_configuration': {'max_training_time': 2},
           'columns': [
               {'name': 'neighbourhood_group', 'included': True, 'model_encoding_type': 'CATEGORICAL'},
               {'name': 'neighbourhood', 'included': True, 'model_encoding_type': 'CATEGORICAL'},
               {'name': 'room_type', 'included': True, 'model_encoding_type': 'CATEGORICAL'},
               {'name': 'price', 'included': True, 'model_encoding_type': 'NUMERIC_AUTO'},
               {'name': 'minimum_nights', 'included': True, 'model_encoding_type': 'NUMERIC_AUTO'},
               {'name': 'number_of_reviews', 'included': True, 'model_encoding_type': 'NUMERIC_AUTO'},
               {'name': 'last_review', 'included': True, 'model_encoding_type': 'DATETIME'},
               {'name': 'reviews_per_month', 'included': True, 'model_encoding_type': 'NUMERIC_AUTO'},
               {'name': 'availability_365', 'included': True, 'model_encoding_type': 'NUMERIC_AUTO'},
               {'name': 'LAT_LONG', 'included': True, 'model_encoding_type': 'LAT_LONG'}
           ]
       }]
   }

   g_airbnb = mostly.train(config=config)
   ```

5. Generate a partially synthetic dataset with the seed.

   ```python filename="python" copy
   # generate a synthetic dataset with a seed
   sd = mostly.generate(generator=g_airbnb, seed=df_seed)

   # start using it
   syn_partial = sd.data()
   print(f"Created synthetic data with {syn_partial.shape[0]:,} records and {syn_partial.shape[1]:,} attributes")
   ```

6. Compare the partial synthetic data to the original data.

   ```python filename="python" copy
   %%capture --no-display
   def plot_manhattan(df, title):
       ax = df_orig.plot.scatter(
           x='longitude',
           y='latitude',
           s=0.1,
           alpha=1,
           color=np.log(df.price.clip(lower=50, upper=2_000)),
           cmap=plt.colormaps['YlOrRd'],
       )
       ax.set_aspect(1.3)
       ax.set_title(title)
       plt.show()

   plot_manhattan(df_orig, 'Original Data')
   plot_manhattan(syn_partial, 'Partially Synthetic Data')
   ```

   <Image src="/docimages/synthetic-datasets/seeded-generation/02-example-01-chart.webp" alt="MOSTLY AI - Usage and credits - Generators usage" width={400} height={500} />

### Generate synthetic names

With the [**Language/Text**](/generators/configure/set-encoding-types#languagetext) encoding type, you can train the **MOSTLY_AI/LSTMFromScratch** model to generate synthetic names. In this example, you will train a generator on the **baseball/players** table and generate the first names and last names of baseball players by using a seed dataset that contains the country of origin of the players.

**Prerequistes**

To reproduce this example, you need the following Python packages.

- [MOSTLY AI Synthetic Data SDK](https://pypi.org/project/mostlyai/)
- [Pandas](https://pandas.pydata.org/)

To install in a Jupyter Notebook environment, use the following:

```bash copy
!pip install mostlyai pandas
```

**Steps**

1. Train a generator with a dataset containing names of people. For this example, we will use the **baseball** dataset.
   1. Create a new generator and add the `players.csv` table from the [baseball dataset](/datasets#baseball-dataset).
      <Image src="/docimages/synthetic-datasets/seeded-generation/03-example-generator-baseball-text-encoding-type.webp" alt="Conditional simulation - Example 03 - Generator with baseball/players table - names set to Language/Text" width={800} height={150} />
      **Step result**: The `nameFirst` and `nameLast` columns have the **Language/Text** encoding type auto-detected.
   2. Click **Configure models**.
   3. Expand the `language` model for the **players** table.
   4. For **Model**, make sure the **MOSTLY_AI/LSTMFromScratch** model is selected.
      <Image src="/docimages/synthetic-datasets/seeded-generation/03-example-generator-configure-model-mostly-ai-lstm.webp" alt="Conditional simulation - Example 03 - Configure model - MOSTLY_AI/LSTMFromScratch" width={800} height={150} />
   5. Click **Start training**.
2. Get the generator ID.
   1. With the generator open, click its kebab menu and select **Copy ID**.
      <Image src="/docimages/synthetic-datasets/seeded-generation/03-example-generator-copy-id.webp" alt="Conditional simulation - Example 03 - Generator - Copy ID" width={800} height={150} />
   2. Past the ID in a Jupyter Notebook or another safe location.
3. In a Jupyter Notebook, live-probe the generator for names from the country Mexico.
   <Callout>The **baseball** dataset contains players from the countries USA, Canada, Mexico, Cuba, and others. The goal is to demonstrate how the LSTM model is able to learn the names of players from specific countries.</Callout>
4. Get the generator by ID.
   ```python filename="python" copy
   g = mostly.generators.get("INSERT_GENERATOR_ID")
   ```
5. Create a seed with 3 rows of the country Mexico.
   ```python filename="python" copy
   seed = pd.DataFrame({
       'country': ['Mexico'] * 5
   })
   ```
6. Live-prove the generator with the seed dataset.
   ```python filename="python" copy
   sp = mostly.generate(g, seed=seed)
   sp[['nameFirst', 'nameLast', 'country']]
   ```

The generator probe returns the following generator names from country Mexico.

```csv
  nameFirst   nameLast country
0     Pedro  Hernandez  Mexico
1   Roberto  Hernandez  Mexico
2     Cesar     Garcia  Mexico
3     Dixie    Ramirez  Mexico
4     Edmon       Pino  Mexico
```

## What's next

With conditional simulation, you can probe generators with a specific context, whether that is hypothetical ([example 1](#rebalance-datasets-with-conditional-simulation)) or real ([example 2](#generate-partially-synthetic-geographical-data)), and gain corresponding insights for specific scenarios. You can also generate synthetic text based on the provided context ([example 3](#generate-synthetic-names)).

In addition, you can:

- use a different set of fixed columns for the US Census dataset
- generate a very large number of records for a fixed value set, e.g. create 1 million records of 48 year old female Professors
- generate a fully synthetic dataset of the AirBnB Manhattan dataset
- [fine-tune an LLM](/quick-start/fine-tuning-llms) with a question answering dataset to then generate synthetic answers based on seeded questions
